{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAE2miXD4IJe8EZPJCSCj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TinyMurky/AnimeFaceDiffusion/blob/main/AnimeFaceDiffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Github Setting"
      ],
      "metadata": {
        "id": "aUR0mHnXqOcr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUniMQXglHm1",
        "outputId": "014ca49d-ca74-4d60-a00e-f372b86661db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ],
      "source": [
        "!git init"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"murky0830@gmail.com\"\n",
        "!git config --global user.name \"TinyMurky\""
      ],
      "metadata": {
        "id": "AyURHm9hl9PF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r \"./sample_data\""
      ],
      "metadata": {
        "id": "rj-fsEtJmMC8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m \"Add import package and text\"\n",
        "# !git remote add origin https://<USERNAME>:<Token>@github.com/<USERNAME>/reponame.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXqFxcgrldrR",
        "outputId": "4cc3e5be-b5a9-4fc4-a548-53ba2e771f5e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "On branch master\n",
            "\n",
            "Initial commit\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31m.config/\u001b[m\n",
            "\t\u001b[31mdrive/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote remove origin\n",
        "!git remote add origin https://TinyMurky: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@github.com/TinyMurky/AnimeFaceDiffusion.git\n",
        "!git branch -M main\n",
        "!git push -u origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCLLgy79nO9T",
        "outputId": "cde4fe0b-ccd0-42f0-cb03-d1dc9cf6b4f1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 28, done.\n",
            "Counting objects:   3% (1/28)\rCounting objects:   7% (2/28)\rCounting objects:  10% (3/28)\rCounting objects:  14% (4/28)\rCounting objects:  17% (5/28)\rCounting objects:  21% (6/28)\rCounting objects:  25% (7/28)\rCounting objects:  28% (8/28)\rCounting objects:  32% (9/28)\rCounting objects:  35% (10/28)\rCounting objects:  39% (11/28)\rCounting objects:  42% (12/28)\rCounting objects:  46% (13/28)\rCounting objects:  50% (14/28)\rCounting objects:  53% (15/28)\rCounting objects:  57% (16/28)\rCounting objects:  60% (17/28)\rCounting objects:  64% (18/28)\rCounting objects:  67% (19/28)\rCounting objects:  71% (20/28)\rCounting objects:  75% (21/28)\rCounting objects:  78% (22/28)\rCounting objects:  82% (23/28)\rCounting objects:  85% (24/28)\rCounting objects:  89% (25/28)\rCounting objects:  92% (26/28)\rCounting objects:  96% (27/28)\rCounting objects: 100% (28/28)\rCounting objects: 100% (28/28), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (20/20), done.\n",
            "Writing objects: 100% (28/28), 8.42 MiB | 1.82 MiB/s, done.\n",
            "Total 28 (delta 5), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (5/5), done.\u001b[K\n",
            "To https://github.com/TinyMurky/AnimeFaceDiffusion.git\n",
            " * [new branch]      main -> main\n",
            "Branch 'main' set up to track remote branch 'main' from 'origin'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git remote add origin https://TinyMurky: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@github.com/TinyMurky/AnimeFaceDiffusion.git\n",
        "!git push "
      ],
      "metadata": {
        "id": "dWC3U_wOuezP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://TinyMurky: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@github.com/TinyMurky/AnimeFaceDiffusion.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaVTn70xqBaK",
        "outputId": "bf1fea24-27c9-4302-e107-131ff6853849"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AnimeFaceDiffusion'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 28 (delta 5), reused 28 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), 8.42 MiB | 3.43 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "_maFnV6Jqvse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive Mount"
      ],
      "metadata": {
        "id": "xROqQYFLqznz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmvzTF5IJ6TL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55633b58-cb4e-4a31-88ce-e78cb20319d3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r \"./sample_data\""
      ],
      "metadata": {
        "id": "HgqBRXcysmzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 主程式開始\n",
        "### 公式：\n",
        "- 訓練公式\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://drive.google.com/uc?id=1LJsdkZ3i1J32lmi9ONMqKFg5LMtpSfT4\" width=\"400\" />\n",
        "</p>\n",
        "$$ \\| \\mathbf{\\epsilon} - \\mathbf{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\|^2 = \\| \\mathbf{\\epsilon} - \\mathbf{\\epsilon}_\\theta( \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{(1- \\bar{\\alpha}_t)  } \\mathbf{\\epsilon}, t) \\|^2.$$\n",
        "- 產圖公式\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?id=1ij80f8TNBDzpKtqHjk_sh8o5aby3lmD7\" width=\"500\" />\n",
        "</p>\n",
        "$$ \\mathbf{x}_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left(  \\mathbf{x}_t - \\frac{1- {\\alpha}_t}{\\sqrt{1- \\bar{\\alpha}_t}} \\mathbf{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right)+\\sigma_tZ$$"
      ],
      "metadata": {
        "id": "l7vpBxbSsrGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 基本套件安裝"
      ],
      "metadata": {
        "id": "DsHhpO4wup8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!pip install transformers\n",
        "!pip install ema_pytorch\n",
        "!pip install accelerate\n",
        "!pip install -q -U datasets matplotlib tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLBnD_ZuuC-T",
        "outputId": "e4610ba8-d62e-43c8-bac0-3cee65f20f39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ema_pytorch\n",
            "  Downloading ema_pytorch-0.2.2-py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.9/dist-packages (from ema_pytorch) (2.0.0+cu118)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.6->ema_pytorch) (3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6->ema_pytorch) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.6->ema_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.6->ema_pytorch) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6->ema_pytorch) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.6->ema_pytorch) (3.10.7)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6->ema_pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6->ema_pytorch) (16.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.6->ema_pytorch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.6->ema_pytorch) (1.3.0)\n",
            "Installing collected packages: ema_pytorch\n",
            "Successfully installed ema_pytorch-0.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate) (5.9.4)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.4.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.4.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.18.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from inspect import isfunction\n",
        "\n",
        "import copy\n",
        "from pathlib import Path\n",
        "from random import random\n",
        "from functools import partial\n",
        "from collections import namedtuple\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.optim import Adam\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms as T, utils\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "from ema_pytorch import EMA\n",
        "\n",
        "from accelerate import Accelerator\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "CmKSVZKUu0mS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seeds Setting"
      ],
      "metadata": {
        "id": "F56BS-4wvpkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "torch.manual_seed(4096)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed(4096)"
      ],
      "metadata": {
        "id": "TqteiHBxvp7l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The neural network\n",
        "\n",
        "The neural network needs to take in a noised image at a particular time step and return the predicted noise. Note that the predicted noise is a tensor that has the same size/resolution as the input image. So technically, the network takes in and outputs tensors of the same shape. What type of neural network can we use for this? \n",
        "\n",
        "What is typically used here is very similar to that of an [Autoencoder](https://en.wikipedia.org/wiki/Autoencoder), which you may remember from typical \"intro to deep learning\" tutorials. Autoencoders have a so-called \"bottleneck\" layer in between the encoder and decoder. The encoder first encodes an image into a smaller hidden representation called the \"bottleneck\", and the decoder then decodes that hidden representation back into an actual image. This forces the network to only keep the most important information in the bottleneck layer.\n",
        "\n",
        "In terms of architecture, the DDPM authors went for a **U-Net**, introduced by ([Ronneberger et al., 2015](https://arxiv.org/abs/1505.04597)) (which, at the time, achieved state-of-the-art results for medical image segmentation). This network, like any autoencoder, consists of a bottleneck in the middle that makes sure the network learns only the most important information. Importantly, it introduced residual connections between the encoder and decoder, greatly improving gradient flow (inspired by ResNet in [He et al., 2015](https://arxiv.org/abs/1512.03385)).\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://drive.google.com/uc?id=1_Hej_VTgdUWGsxxIuyZACCGjpbCGIUi6\" width=\"400\" />\n",
        "</p>\n",
        "\n",
        "As can be seen, a U-Net model first downsamples the input (i.e. makes the input smaller in terms of spatial resolution), after which upsampling is performed.\n",
        "\n",
        "Below, we implement this network, step-by-step.\n"
      ],
      "metadata": {
        "id": "05tBrGY5wA3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Network helpers\n",
        "\n",
        "First, we define some helper functions and classes which will be used when implementing the neural network. Importantly, we define a `Residual` module, which simply adds the input to the output of a particular function (in other words, adds a residual connection to a particular function).\n",
        "\n",
        "We also define aliases for the up- and downsampling operations."
      ],
      "metadata": {
        "id": "pqVHl1yEwIz1"
      }
    }
  ]
}